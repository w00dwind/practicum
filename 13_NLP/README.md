# Обучение модели классификации комментариев

Интернет-магазин «Викишоп» запускает новый сервис. Теперь пользователи могут редактировать и дополнять описания товаров, как в вики-сообществах. То есть клиенты предлагают свои правки и комментируют изменения других. Магазину нужен инструмент, который будет искать токсичные комментарии и отправлять их на модерацию.

Метрика - f1

### Данные:

Датасет - toxic_comments.csv
    Признаки:
        text - комментарий.
        toxic - токсичный или нет.
        
### Ход исследования:
- В ходе исследования комментарии были очищены от случайных занков, стоп слов и лемматезированы.
- Закодированы с помощью Tf-idf
- Обучены базовые алгоритмы: LogisticRegression, RandomForest, lightGBM
- Среди базовых алгоритмов наилучшим образом проявил себя lightGBM с метрикой f1 0.7463
- Подбор порога вероятности дал прирост к качеству lightGBM, итоговый результат = 0.7728 при пороге 0.3

## Bert
- Все функции упакованы в отдельный файл func.py
- Для борьбы с дисбалансом классов была попытка расчитать веса классов и исаользовать WeightedRandomSampler, однако это не дало прирост к качеству, по сравнению с обыкновенным RandomSampler
- Для обучения Bert было запущено два эксперимента:
    - В первом использовалась предтренированная модель Bert, без изменения классификатора (последнего слоя). Модель стала переобучаться на первой же эпохе, продолжив эту тенденцию.
    - Во втором эксперменти к модли Bert было добавлено два слоя Dropout(0.5) - для предотвращения переобучения и Linear - для классификации. Этот эксперимент показал себя лучше, хотя и тоже имел признаки переобучения после первой эпохи.
- Наилучший результат удалось достичь в рамках второго эксперимента с метрикой f1 на тестовой выборке = 0.849
- Можно и дальше продолжать эксперименты и достичь прироста метрики, однако в рамках данной задачи, мы с запасом выполнили требования заказчика. 

