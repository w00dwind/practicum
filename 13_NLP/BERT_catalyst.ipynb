{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f64611b4",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Config\" data-toc-modified-id=\"Config-1\">Config</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d245a4d",
   "metadata": {
    "id": "4d245a4d"
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "xvSOxsRa1Qfg",
   "metadata": {
    "id": "xvSOxsRa1Qfg"
   },
   "source": [
    "## Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8edc73b3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-13T13:23:07.429266Z",
     "start_time": "2022-10-13T13:23:07.426805Z"
    },
    "id": "8edc73b3"
   },
   "outputs": [],
   "source": [
    "# Configuration\n",
    "\n",
    "\n",
    "MODEL_NAME = 'bert-base-uncased'\n",
    "PROJECT_NAME = 'toxic_comment_detection'\n",
    "LOG_DIR = \"logdir\"\n",
    "\n",
    "PERC_OF_DATA = 80 # percent of data to use\n",
    "BATCH_SIZE = 20\n",
    "EPOCHS = 4\n",
    "NUM_CLASSES = 2\n",
    "LEARNING_RATE = 3e-5 \n",
    "NUM_WORKERS = 2\n",
    "SEED = 42\n",
    "\n",
    "WANDB = False # if True, install and use wandb logger\n",
    "COLAB_MODE = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3ziK8rFHu1h4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-13T13:23:09.572738Z",
     "start_time": "2022-10-13T13:23:07.435810Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3ziK8rFHu1h4",
    "outputId": "1d2c20d6-fec5-4ba9-995d-0770fa3191af"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mDEPRECATION: Configuring installation scheme with distutils config files is deprecated and will no longer work in the near future. If you are using a Homebrew or Linuxbrew Python, please see discussion at https://github.com/Homebrew/homebrew-core/issues/76621\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: transformers in /usr/local/lib/python3.9/site-packages (4.20.1)\n",
      "Requirement already satisfied: catalyst in /usr/local/lib/python3.9/site-packages (22.4)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.9/site-packages (from transformers) (1.21.5)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.9/site-packages (from transformers) (6.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/site-packages (from transformers) (21.3)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.9/site-packages (from transformers) (2.26.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.9/site-packages (from transformers) (2022.4.24)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.9/site-packages (from transformers) (0.8.1)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.9/site-packages (from transformers) (3.7.1)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.9/site-packages (from transformers) (4.63.0)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /usr/local/lib/python3.9/site-packages (from transformers) (0.12.1)\n",
      "Requirement already satisfied: tensorboardX>=2.1.0 in /usr/local/lib/python3.9/site-packages (from catalyst) (2.5.1)\n",
      "Requirement already satisfied: accelerate>=0.5.1 in /usr/local/lib/python3.9/site-packages (from catalyst) (0.10.0)\n",
      "Requirement already satisfied: torch>=1.4.0 in /usr/local/lib/python3.9/site-packages (from catalyst) (1.12.0)\n",
      "Requirement already satisfied: hydra-slayer>=0.4.0 in /usr/local/lib/python3.9/site-packages (from catalyst) (0.4.0)\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.9/site-packages (from accelerate>=0.5.1->catalyst) (5.9.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.9/site-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (4.1.1)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.9/site-packages (from packaging>=20.0->transformers) (3.0.6)\n",
      "Requirement already satisfied: protobuf<=3.20.1,>=3.8.0 in /usr/local/lib/python3.9/site-packages (from tensorboardX>=2.1.0->catalyst) (3.19.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/site-packages (from requests->transformers) (2021.10.8)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/site-packages (from requests->transformers) (1.26.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/site-packages (from requests->transformers) (3.3)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/site-packages (from requests->transformers) (2.0.9)\n",
      "\u001b[33mDEPRECATION: Configuring installation scheme with distutils config files is deprecated and will no longer work in the near future. If you are using a Homebrew or Linuxbrew Python, please see discussion at https://github.com/Homebrew/homebrew-core/issues/76621\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install transformers catalyst\n",
    "if WANDB:\n",
    "    !pip install wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "38c2abd7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-19T20:40:38.603795Z",
     "start_time": "2023-02-19T20:40:34.289234Z"
    },
    "id": "38c2abd7"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'catalyst'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 17\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DataLoader, TensorDataset\n\u001b[0;32m---> 17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcatalyst\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m dl\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnn\u001b[39;00m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcatalyst\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcontrib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlosses\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfocal\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m FocalLossBinary\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'catalyst'"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import os\n",
    "from typing import List, Mapping, Tuple\n",
    "import logging\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import notebook\n",
    "\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from transformers import AutoTokenizer\n",
    "# Transformers \n",
    "from transformers import AutoConfig, AutoModel, AutoTokenizer, PreTrainedTokenizerFast\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from catalyst import dl\n",
    "import torch.nn as nn\n",
    "from catalyst.contrib.losses.focal import FocalLossBinary\n",
    "\n",
    "from catalyst.dl import (\n",
    "    CheckpointCallback,\n",
    "    OptimizerCallback,\n",
    "    SchedulerCallback,\n",
    "    SupervisedRunner,\n",
    "    AccuracyCallback,\n",
    "    PrecisionRecallF1SupportCallback\n",
    ")\n",
    "\n",
    "import platform\n",
    "\n",
    "def choose_device(platform:str) -> str:\n",
    "    if platform == 'Darwin':\n",
    "        return 'mps'\n",
    "    elif platform == 'Linux' and torch.cuda.is_avaliable():\n",
    "        return 'cuda'\n",
    "    else:\n",
    "        return 'cpu'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "P8aWuqdE3gXe",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-13T13:23:11.692899Z",
     "start_time": "2022-10-13T13:23:11.690483Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "P8aWuqdE3gXe",
    "outputId": "d53fe465-8207-48cc-842f-837e5855fc00"
   },
   "outputs": [],
   "source": [
    "if COLAB_MODE:\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "\n",
    "\n",
    "    COLAB_ROOT = Path('drive/MyDrive/Colab_Notebooks/', PROJECT_NAME)\n",
    "\n",
    "    #Optional: move to the desired location:\n",
    "    %cd $COLAB_ROOT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5137f82a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-13T13:23:12.403970Z",
     "start_time": "2022-10-13T13:23:11.694246Z"
    },
    "id": "5137f82a"
   },
   "outputs": [],
   "source": [
    "local_path = '../datasets/toxic_comments.csv'\n",
    "cloud_path = '/datasets/toxic_comments.csv'\n",
    "colab_path = '../datasets/toxic_comments.csv'\n",
    "\n",
    "if os.path.exists(local_path):\n",
    "    df = pd.read_csv(local_path)\n",
    "elif os.path.exists(cloud_path):\n",
    "    df = pd.read_csv(cloud_path)\n",
    "elif os.path.exists(colab_path):\n",
    "    df = pd.read_csv(colab_path)\n",
    "else:\n",
    "    print('something wrong! Check path')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7f05b60a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-13T13:23:12.410825Z",
     "start_time": "2022-10-13T13:23:12.405330Z"
    },
    "id": "7f05b60a"
   },
   "outputs": [],
   "source": [
    "class TextClassificationDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Wrapper around Torch Dataset to perform text classification\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        texts: List[str],\n",
    "        labels: np.array = None,\n",
    "        max_seq_length: int = 256,\n",
    "        model_name: str = MODEL_NAME,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            texts (List[str]): a list with texts to classify or to train the\n",
    "                classifier on\n",
    "            labels List[str]: a list with classification labels (optional)\n",
    "            label_dict (dict): a dictionary mapping class names to class ids,\n",
    "                to be passed to the validation data (optional)\n",
    "            max_seq_length (int): maximal sequence length in tokens,\n",
    "                texts will be stripped to this length\n",
    "            model_name (str): transformer model name, needed to perform\n",
    "                appropriate tokenization\n",
    "        \"\"\"\n",
    "\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "        self.max_seq_length = max_seq_length\n",
    "\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "        self.model_name = model_name\n",
    "\n",
    "        # suppresses tokenizer warnings\n",
    "        logging.getLogger(\"transformers.tokenization_utils\").setLevel(logging.FATAL)\n",
    "\n",
    "        # special tokens for transformers\n",
    "        # in the simplest case a [CLS] token is added in the beginning\n",
    "        # and [SEP] token is added in the end of a piece of text\n",
    "        # [CLS] <indexes text tokens> [SEP] .. <[PAD]>\n",
    "\n",
    "        self.sep_vid = self.tokenizer.vocab[\"[SEP]\"]\n",
    "        self.cls_vid = self.tokenizer.vocab[\"[CLS]\"]\n",
    "        self.pad_vid = self.tokenizer.vocab[\"[PAD]\"]\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        \"\"\"\n",
    "        Returns:\n",
    "            int: length of the dataset\n",
    "        \"\"\"\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, index) -> Mapping[str, torch.Tensor]:\n",
    "        \"\"\"Gets element of the dataset\n",
    "        Args:\n",
    "            index (int): index of the element in the dataset\n",
    "        Returns:\n",
    "            Single element by index\n",
    "        \"\"\"\n",
    "\n",
    "        # encoding the text\n",
    "        x = self.texts[index]\n",
    "\n",
    "        # a dictionary with `input_ids` and `attention_mask` as keys\n",
    "        output_dict = self.tokenizer.encode_plus(\n",
    "            x,\n",
    "            add_special_tokens=True,\n",
    "            padding='max_length',\n",
    "            max_length=self.max_seq_length,\n",
    "            truncation=True,\n",
    "            return_tensors=\"pt\",\n",
    "            return_attention_mask=True,\n",
    "        )\n",
    "\n",
    "        # for Catalyst, there needs to be a key called features\n",
    "        output_dict['features'] = output_dict['input_ids'].squeeze()\n",
    "        del output_dict['input_ids']\n",
    "\n",
    "        return {\n",
    "                'attention_mask': output_dict['attention_mask'].squeeze(),\n",
    "                'features': output_dict['features'].squeeze(),\n",
    "                'targets': torch.tensor(self.labels[index].squeeze())\n",
    "                }\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4920207b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-13T13:23:12.458559Z",
     "start_time": "2022-10-13T13:23:12.411769Z"
    },
    "id": "4920207b"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "sample = df.sample(frac=PERC_OF_DATA / 100)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    sample['text'],\n",
    "    sample['toxic'].values,\n",
    "    test_size=.3,\n",
    "    stratify=sample['toxic'].values\n",
    ")\n",
    "\n",
    "X_valid, X_test, y_valid, y_test = train_test_split(\n",
    "    X_test,\n",
    "    y_test,\n",
    "    test_size=.5,\n",
    "    stratify=y_test\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "OCBr9hH7AW7L",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-13T13:23:12.633201Z",
     "start_time": "2022-10-13T13:23:12.459470Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OCBr9hH7AW7L",
    "outputId": "3f6d5623-2226-44f3-e600-2cabfa93a4af"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8983650219899506, 0.8983758943025746)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check class balance\n",
    "sum(y_train == 0) / len(y_train), sum(y_test == 0) / len(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7067a54c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-13T13:23:28.139921Z",
     "start_time": "2022-10-13T13:23:12.634167Z"
    },
    "id": "7067a54c"
   },
   "outputs": [],
   "source": [
    "train_dataset = TextClassificationDataset(\n",
    "    texts=X_train.values.tolist(),\n",
    "    labels=y_train,\n",
    "                               )\n",
    "\n",
    "valid_dataset = TextClassificationDataset(\n",
    "    texts=X_valid.values,\n",
    "    labels=y_valid\n",
    ")\n",
    "\n",
    "test_dataset = TextClassificationDataset(\n",
    "    texts=X_test.values.tolist(),\n",
    "    labels=y_test\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "19e0121e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-13T13:23:28.143724Z",
     "start_time": "2022-10-13T13:23:28.140900Z"
    },
    "id": "19e0121e"
   },
   "outputs": [],
   "source": [
    "# creating PyTorch data loaders and placing them in dictionaries (for Catalyst)\n",
    "train_val_loaders = {\n",
    "        \"train\": DataLoader(\n",
    "            dataset=train_dataset,\n",
    "            batch_size=BATCH_SIZE,\n",
    "            shuffle=True,\n",
    "            num_workers=NUM_WORKERS\n",
    "        ),\n",
    "        \"valid\": DataLoader(\n",
    "            dataset=valid_dataset,\n",
    "            batch_size=BATCH_SIZE,\n",
    "            shuffle=False,\n",
    "            num_workers=NUM_WORKERS\n",
    "        ),\n",
    "    }\n",
    "\n",
    "test_loaders = {\n",
    "        \"test\": DataLoader(\n",
    "            dataset=test_dataset,\n",
    "            batch_size=BATCH_SIZE,\n",
    "            shuffle=False,\n",
    "            num_workers=NUM_WORKERS\n",
    "        )\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "SDICT1CwOQlu",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-13T13:23:28.150481Z",
     "start_time": "2022-10-13T13:23:28.146382Z"
    },
    "id": "SDICT1CwOQlu"
   },
   "outputs": [],
   "source": [
    "class BertForSequenceClassification(nn.Module):\n",
    "    \"\"\"\n",
    "    Simplified version of the same class by HuggingFace.\n",
    "    See transformers/modeling_distilbert.py in the transformers repository.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, pretrained_model_name: str, num_classes: int = NUM_CLASSES, dropout: float = 0.3):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            pretrained_model_name (str): HuggingFace model name.\n",
    "                See transformers/modeling_auto.py\n",
    "            num_classes (int): the number of class labels\n",
    "                in the classification task\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "\n",
    "        config = AutoConfig.from_pretrained(\n",
    "            pretrained_model_name, num_labels=NUM_CLASSES)\n",
    "\n",
    "        self.model = AutoModel.from_pretrained(pretrained_model_name,\n",
    "                                                    config=config)\n",
    "#         self.pre_classifier = nn.Linear(config.hidden_size, config.hidden_size)\n",
    "        self.classifier = nn.Linear(config.hidden_size, num_classes)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, features, attention_mask=None, head_mask=None):\n",
    "        \"\"\"Compute class probabilities for the input sequence.\n",
    "\n",
    "        Args:\n",
    "            features (torch.Tensor): ids of each token,\n",
    "                size ([bs, seq_length]\n",
    "            attention_mask (torch.Tensor): binary tensor, used to select\n",
    "                tokens which are used to compute attention scores\n",
    "                in the self-attention heads, size [bs, seq_length]\n",
    "            head_mask (torch.Tensor): 1.0 in head_mask indicates that\n",
    "                we keep the head, size: [num_heads]\n",
    "                or [num_hidden_layers x num_heads]\n",
    "        Returns:\n",
    "            PyTorch Tensor with predicted class probabilities\n",
    "        \"\"\"\n",
    "        assert attention_mask is not None, \"attention mask is none\"\n",
    "        \n",
    "        bert_output = self.model(input_ids=features,\n",
    "                                            attention_mask=attention_mask,\n",
    "                                            head_mask=head_mask)\n",
    "        # we only need the hidden state here and don't need\n",
    "        # transformer output, so index 0\n",
    "        seq_output = bert_output[0]  # (bs, seq_len, dim)\n",
    "        # mean pooling, i.e. getting average representation for all tokens\n",
    "        pooled_output = seq_output.mean(axis=1)  # (bs, dim)\n",
    "        pooled_output = self.dropout(pooled_output)  # (bs, dim)\n",
    "        logits = self.classifier(pooled_output)  # (bs, dim)\n",
    "\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "094c296f",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-10-13T13:23:07.587Z"
    },
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/",
     "height": 239,
     "referenced_widgets": [
      "f2c1ce0b87524c9980a7c3a19039d58f",
      "710b1b9c3c414da998880d8e459d34bc",
      "efce6b6591ac4fe89bc7cba2c00ad059",
      "1450925f95884f42bb809ad61d449dd1",
      "baa42346260c40389de3056dcc20a485",
      "99995acd8615482ca63b7de64c346365",
      "70463cb292b0440eab0fa4d3b0e2d196",
      "d1813206820c4889bc5e4e35c80970b3",
      "72af9ffdd2be4aff86316401d82e111d",
      "75d8425728114b54a24fe9d8120e7f30",
      "7052f943a0804bf98a6384c0aa65790c"
     ]
    },
    "id": "094c296f",
    "outputId": "7b9605b6-dd3e-429a-8c14-ee99d16b15ce"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c1e017587e6496f9365c3f031a95428",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "1/4 * Epoch (train):   0%|          | 0/4468 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"<string>\", line 1, in <module>\n",
      "  File \"/usr/local/Cellar/python@3.9/3.9.13_3/Frameworks/Python.framework/Versions/3.9/lib/python3.9/multiprocessing/spawn.py\", line 116, in spawn_main\n",
      "    exitcode = _main(fd, parent_sentinel)\n",
      "  File \"/usr/local/Cellar/python@3.9/3.9.13_3/Frameworks/Python.framework/Versions/3.9/lib/python3.9/multiprocessing/spawn.py\", line 126, in _main\n",
      "    self = reduction.pickle.load(from_parent)\n",
      "AttributeError: Can't get attribute 'TextClassificationDataset' on <module '__main__' (built-in)>\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# model = BertForSequenceClassification.from_pretrained(MODEL_NAME)\n",
    "model = BertForSequenceClassification(pretrained_model_name=MODEL_NAME,\n",
    "                                      num_classes=NUM_CLASSES)\n",
    "\n",
    "# specify criterion for the multi-class classification task, optimizer and scheduler\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "# criterion = FocalLossBinary()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer)\n",
    "\n",
    "# reproducibility\n",
    "torch.manual_seed(SEED)\n",
    "# prepare_cudnn(deterministic=True)\n",
    "\n",
    "# here we specify that we pass masks to the runner. So model's forward method will be called with\n",
    "# these arguments passed to it.\n",
    "# model training\n",
    "runner = SupervisedRunner(\n",
    "    input_key=(\"features\", \"attention_mask\")\n",
    "    )\n",
    "\n",
    "# finally, training the model with Catalyst\n",
    "runner.train(\n",
    "    model=model,\n",
    "    criterion=criterion,\n",
    "    optimizer=optimizer,\n",
    "    scheduler=scheduler,\n",
    "    loaders=train_val_loaders,\n",
    "    callbacks=[\n",
    "        AccuracyCallback(num_classes=2, input_key=\"logits\", target_key=\"targets\"),\n",
    "        PrecisionRecallF1SupportCallback(\n",
    "            input_key=\"logits\", target_key=\"targets\", num_classes=NUM_CLASSES\n",
    "        ),\n",
    "        OptimizerCallback(accumulation_steps=4, metric_key=\"loss\"),\n",
    "        SchedulerCallback(loader_key=\"valid\", metric_key=\"loss\"),\n",
    "        CheckpointCallback(logdir=LOG_DIR, loader_key=\"valid\", metric_key=\"loss\", minimize=True),\n",
    "    ],\n",
    "     loggers={\"wandb\": dl.WandbLogger(project=PROJECT_NAME, name=f\"{MODEL_NAME}_catalyst\")} if WANDB else None,\n",
    "    logdir=LOG_DIR,\n",
    "    num_epochs=EPOCHS,\n",
    "    verbose = True\n",
    ")\n",
    "\n",
    "# and running inference\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "# getting validation metrics\n",
    "metrics = runner.evaluate_loader(\n",
    "    loader=train_val_loaders[\"valid\"],\n",
    "    callbacks=[PrecisionRecallF1SupportCallback(\n",
    "            input_key=\"logits\", target_key=\"targets\", num_classes=NUM_CLASSES\n",
    "        )],\n",
    ")\n",
    "print(metrics)\n",
    "\n",
    "# lastly, saving predicted scores for the test set\n",
    "# test_pred_scores = np.concatenate(\n",
    "#     [pred[\"logits\"].detach().cpu().numpy() for pred in runner.predict_loader(loader=test_loaders[\"test\"])]\n",
    "# )\n",
    "\n",
    "\n",
    "# np.savetxt(X=test_pred_scores, fname=Path(LOG_DIR / 'pred.txt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ZES1j7YPjYuK",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-10-13T13:23:07.600Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZES1j7YPjYuK",
    "outputId": "adac20b6-5682-43e8-9298-eb80015da444"
   },
   "outputs": [],
   "source": [
    "import tensorboard\n",
    "from tensorboard import notebook\n",
    "notebook.list() # View open TensorBoard instances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "kE9qaFVMY5wo",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-10-13T13:23:07.605Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kE9qaFVMY5wo",
    "outputId": "4e84e8c2-a946-4a86-b5d5-316c27cd9bd6"
   },
   "outputs": [],
   "source": [
    "!ls "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "MHK4cdt7Wtaq",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-10-13T13:23:07.613Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MHK4cdt7Wtaq",
    "outputId": "6b8ead2f-4445-4fef-c3f4-c76142a0a7b1"
   },
   "outputs": [],
   "source": [
    "!tensorboard dev upload \\\n",
    "  --logdir logdir/tensorboard/ \\\n",
    "  --name \"catalyst_bert_full_dataset\" \\\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ktmuLF4aYA_s",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-10-13T13:23:07.620Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ktmuLF4aYA_s",
    "outputId": "ff7b5740-74b6-48ef-cda5-f98adfa01154"
   },
   "outputs": [],
   "source": [
    "!tensorboard --logdir /logdir/tensorboard/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "-twowKzSZ_yY",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-10-13T13:23:07.626Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-twowKzSZ_yY",
    "outputId": "9f70a6e2-e285-48e0-d6f4-dc7a87aca89e"
   },
   "outputs": [],
   "source": [
    "!ls logdir/tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8zDoQY01aC03",
   "metadata": {
    "id": "8zDoQY01aC03"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "nbTranslate": {
   "displayLangs": [
    "*"
   ],
   "hotkey": "alt-t",
   "langInMainMenu": true,
   "sourceLang": "en",
   "targetLang": "fr",
   "useGoogleTranslate": true
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "1450925f95884f42bb809ad61d449dd1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_75d8425728114b54a24fe9d8120e7f30",
      "placeholder": "​",
      "style": "IPY_MODEL_7052f943a0804bf98a6384c0aa65790c",
      "value": " 30/4468 [00:24&lt;57:26,  1.29it/s, accuracy01=0.900, f1/_macro=0.474, f1/_micro=0.900, f1/_weighted=0.853, loss=0.321, lr=3.000e-05, momentum=0.900, precision/_macro=0.450, precision/_micro=0.900, precision/_weighted=0.810, recall/_macro=0.500, recall/_micro=0.900, recall/_weighted=0.900]"
     }
    },
    "70463cb292b0440eab0fa4d3b0e2d196": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "7052f943a0804bf98a6384c0aa65790c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "710b1b9c3c414da998880d8e459d34bc": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_99995acd8615482ca63b7de64c346365",
      "placeholder": "​",
      "style": "IPY_MODEL_70463cb292b0440eab0fa4d3b0e2d196",
      "value": "1/4 * Epoch (train):   1%"
     }
    },
    "72af9ffdd2be4aff86316401d82e111d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "75d8425728114b54a24fe9d8120e7f30": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "99995acd8615482ca63b7de64c346365": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "baa42346260c40389de3056dcc20a485": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d1813206820c4889bc5e4e35c80970b3": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "efce6b6591ac4fe89bc7cba2c00ad059": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d1813206820c4889bc5e4e35c80970b3",
      "max": 4468,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_72af9ffdd2be4aff86316401d82e111d",
      "value": 30
     }
    },
    "f2c1ce0b87524c9980a7c3a19039d58f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_710b1b9c3c414da998880d8e459d34bc",
       "IPY_MODEL_efce6b6591ac4fe89bc7cba2c00ad059",
       "IPY_MODEL_1450925f95884f42bb809ad61d449dd1"
      ],
      "layout": "IPY_MODEL_baa42346260c40389de3056dcc20a485"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
